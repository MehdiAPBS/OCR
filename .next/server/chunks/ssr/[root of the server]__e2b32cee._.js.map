{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 215, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/genkit.ts"],"sourcesContent":["import {genkit} from 'genkit';\nimport {googleAI} from '@genkit-ai/googleai';\n\nexport const ai = genkit({\n  plugins: [googleAI()],\n  model: 'googleai/gemini-2.0-flash',\n});\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAEO,MAAM,KAAK,CAAA,GAAA,uIAAA,CAAA,SAAM,AAAD,EAAE;IACvB,SAAS;QAAC,CAAA,GAAA,2KAAA,CAAA,WAAQ,AAAD;KAAI;IACrB,OAAO;AACT","debugId":null}},
    {"offset": {"line": 292, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/schemas/pdf-data-schema.ts"],"sourcesContent":["\nimport { z } from 'zod';\n\n// Schema for the actual structured data the AI should extract\nexport const ExtractedPdfDataSchema = z.object({\n  classe: z.string().describe('The class name. Return \"\" if not found.'),\n  cours: z.string().describe('The course name. Return \"\" if not found.'),\n  date: z.string().describe('The date of the session. Return \"\" if not found.'),\n  nom_du_professeur: z.string().describe(\"The professor's name. Return \\\"\\\" if not found.\"),\n  nombre_des_présents: z.number().describe('The number of present students. Return 0 if not found.'),\n  salle_n: z.string().describe('The room number. Return \"\" if not found.'),\n  séance: z.string().describe('The session information. Return \"\" if not found.'),\n  présences: z.array(z.object({\n    n: z.string().describe('The student number or ID. Return \"\" if not found.'),\n    nom_prénom: z.string().describe(\"The student's full name. Return \\\"\\\" if not found.\"),\n  })).describe('An array representing the attendees. Return [] if not found or if data is missing for all attendees.'),\n});\nexport type ExtractedPdfData = z.infer<typeof ExtractedPdfDataSchema>;\n"],"names":[],"mappings":";;;AACA;;AAGO,MAAM,yBAAyB,oIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC7C,QAAQ,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC5B,OAAO,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC3B,MAAM,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC1B,mBAAmB,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACvC,qBAAqB,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IACzC,SAAS,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B,QAAQ,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC5B,WAAW,oIAAA,CAAA,IAAC,CAAC,KAAK,CAAC,oIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;QAC1B,GAAG,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QACvB,YAAY,oIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAClC,IAAI,QAAQ,CAAC;AACf","debugId":null}},
    {"offset": {"line": 316, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/extract-data-from-pdf.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview Extracts data from a PDF using AI (Genkit), with an option for Google Cloud Vision OCR.\n *\n * - extractDataFromPdf - A function that handles the data extraction process.\n * - ExtractDataFromPdfInput - The input type for the extractDataFromPdf function.\n * - ExtractDataFromPdfOutput - The return type for the extractDataFromPdf function.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport { ImageAnnotatorClient } from '@google-cloud/vision';\nimport type { ExtractedPdfData } from '@/ai/schemas/pdf-data-schema'; \nimport { ExtractedPdfDataSchema } from '@/ai/schemas/pdf-data-schema'; \n\n// Schema for the overall flow input\nconst ExtractDataFromPdfInputSchema = z.object({\n  pdfDataUri: z.string().describe(\n    \"The PDF document, as a data URI that must include a MIME type and use Base64 encoding. Expected format: 'data:<mimetype>;base64,<encoded_data>'.\"\n  ),\n  extractionEngine: z.enum(['genkitDirect', 'googleCloudVision'])\n    .default('genkitDirect')\n    .describe('The engine to use for PDF data extraction.'),\n});\nexport type ExtractDataFromPdfInput = z.infer<typeof ExtractDataFromPdfInputSchema>;\n\n// Schema for the flow's final output to the frontend\nconst ExtractDataFromPdfOutputSchema = z.object({\n  jsonOutput: z.string().describe('The extracted data from the PDF, as a JSON string.'),\n  error: z.string().optional().describe('An error message if extraction failed.'),\n});\nexport type ExtractDataFromPdfOutput = z.infer<typeof ExtractDataFromPdfOutputSchema>;\n\nexport async function extractDataFromPdf(input: ExtractDataFromPdfInput): Promise<ExtractDataFromPdfOutput> {\n  return extractDataFromPdfFlow(input);\n}\n\n// Prompt for direct PDF processing by Genkit AI\nconst genkitDirectPdfProcessPrompt = ai.definePrompt({\n  name: 'genkitDirectPdfProcessPrompt',\n  input: { schema: z.object({ pdfDataUri: ExtractDataFromPdfInputSchema.shape.pdfDataUri }) },\n  output: { schema: ExtractedPdfDataSchema },\n  prompt: `You are an expert data extraction specialist.\nYou will receive a PDF document. Your task is to analyze this document and extract all the relevant information from it.\nReturn the extracted data as a JSON object strictly conforming to the provided schema.\n\nCRITICAL INSTRUCTION FOR HANDLING MISSING DATA:\n- For all string fields (e.g., \\`classe\\`, \\`cours\\`, \\`date\\`, \\`nom_du_professeur\\`, \\`salle_n\\`, \\`séance\\`, and within \\`présences\\`: \\`n\\`, \\`nom_prénom\\`), if the information cannot be found or determined from the PDF, you MUST use an empty string \\`\"\"\\` as its value for that field.\n- For the \\`nombre_des_présents\\` field (a number), if it cannot be determined, you MUST use the number \\`0\\` as its value.\n- For the \\`présences\\` array, if no attendees are found or the data is missing for all attendees, you MUST use an empty array \\`[]\\` as its value. If some attendees are found but some details are missing for an individual attendee, apply the empty string rule for their \\`n\\` or \\`nom_prénom\\` fields.\n- DO NOT OMIT ANY KEYS specified in the schema. The goal is to always return a JSON object that strictly conforms to the defined structure, using these empty/default values for missing information.\n\nPDF Document:\n{{media url=pdfDataUri}}`,\n});\n\n// Prompt for structuring text extracted by an external OCR (like Google Cloud Vision)\nconst structureOcrTextPrompt = ai.definePrompt({\n  name: 'structureOcrTextPrompt',\n  input: { schema: z.object({ ocrText: z.string().describe(\"Text extracted from a document by an OCR engine.\") }) },\n  output: { schema: ExtractedPdfDataSchema },\n  prompt: `You are an expert data extraction specialist.\nYou will receive text that has been extracted from a document using an OCR engine. Your task is to analyze this text and extract all the relevant information from it.\nReturn the extracted data as a JSON object strictly conforming to the provided schema.\n\nCRITICAL INSTRUCTION FOR HANDLING MISSING DATA:\n- For all string fields (e.g., \\`classe\\`, \\`cours\\`, \\`date\\`, \\`nom_du_professeur\\`, \\`salle_n\\`, \\`séance\\`, and within \\`présences\\`: \\`n\\`, \\`nom_prénom\\`), if the information cannot be found or determined from the text, you MUST use an empty string \\`\"\"\\` as its value for that field.\n- For the \\`nombre_des_présents\\` field (a number), if it cannot be determined, you MUST use the number \\`0\\` as its value.\n- For the \\`présences\\` array, if no attendees are found or the data is missing for all attendees, you MUST use an empty array \\`[]\\` as its value. If some attendees are found but some details are missing for an individual attendee, apply the empty string rule for their \\`n\\` or \\`nom_prénom\\` fields.\n- DO NOT OMIT ANY KEYS specified in the schema. The goal is to always return a JSON object that strictly conforms to the defined structure, using these empty/default values for missing information.\n\nOCR'd Text:\n{{{ocrText}}}`,\n});\n\n\nconst extractDataFromPdfFlow = ai.defineFlow(\n  {\n    name: 'extractDataFromPdfFlow',\n    inputSchema: ExtractDataFromPdfInputSchema,\n    outputSchema: ExtractDataFromPdfOutputSchema, \n  },\n  async (flowInput) => {\n    console.log(`Starting PDF data extraction with engine: ${flowInput.extractionEngine}`);\n\n    const defaultEmptyStructuredData: ExtractedPdfData = {\n      classe: \"\", cours: \"\", date: \"\", nom_du_professeur: \"\",\n      nombre_des_présents: 0, salle_n: \"\", séance: \"\", présences: [],\n    };\n    const defaultEmptyJsonOutputString = JSON.stringify(defaultEmptyStructuredData);\n\n    try {\n      let structuredData: ExtractedPdfData | null = null;\n\n      if (flowInput.extractionEngine === 'googleCloudVision') {\n        console.log('Using Google Cloud Vision OCR engine.');\n        const serviceAccountCredsJsonString = process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS_JSON;\n        if (!serviceAccountCredsJsonString) {\n          return { jsonOutput: defaultEmptyJsonOutputString, error: 'Google Service Account credentials are not configured for Vision API.' };\n        }\n\n        let visionCredentials;\n        try {\n          visionCredentials = JSON.parse(serviceAccountCredsJsonString);\n           if (visionCredentials && visionCredentials.private_key) {\n             visionCredentials.private_key = visionCredentials.private_key.replace(/\\\\n/g, '\\n');\n           }\n        } catch (e: any) {\n          console.error('Failed to parse Google Service Account credentials for Vision API:', e.message);\n          return { jsonOutput: defaultEmptyJsonOutputString, error: `Invalid Google Service Account credentials format for Vision API: ${e.message}` };\n        }\n        \n        const visionClient = new ImageAnnotatorClient({ credentials: visionCredentials });\n        \n        const base64PdfData = flowInput.pdfDataUri.substring(flowInput.pdfDataUri.indexOf(',') + 1);\n        \n        const request = {\n          requests: [\n            {\n              inputConfig: {\n                content: base64PdfData,\n                mimeType: 'application/pdf',\n              },\n              features: [{ type: 'DOCUMENT_TEXT_DETECTION' }],\n            },\n          ],\n        };\n\n        console.log('Sending PDF to Google Cloud Vision API for OCR...');\n        const [visionResult] = await visionClient.batchAnnotateFiles(request as any); // Cast to any to match SDK\n        const responses = visionResult.responses?.[0]?.responses;\n\n        if (!responses || responses.length === 0 || !responses[0].fullTextAnnotation) {\n          console.error('Google Cloud Vision API did not return text annotation.');\n          return { jsonOutput: defaultEmptyJsonOutputString, error: 'Google Cloud Vision OCR did not return text. The PDF might be image-only or unreadable by OCR.' };\n        }\n        \n        const ocrText = responses[0].fullTextAnnotation.text || \"\";\n        console.log('OCR Text from Vision API (first 500 chars):', ocrText.substring(0, 500));\n\n        if (!ocrText.trim()) {\n            console.warn('Vision API returned empty text from OCR.');\n            return { jsonOutput: defaultEmptyJsonOutputString, error: 'Google Cloud Vision OCR returned empty text.' };\n        }\n\n        const { output: visionStructuredData } = await structureOcrTextPrompt({ ocrText });\n        structuredData = visionStructuredData;\n\n      } else { // Default to 'genkitDirect'\n        console.log('Using Genkit Direct AI engine.');\n        const { output: genkitStructuredData } = await genkitDirectPdfProcessPrompt({ pdfDataUri: flowInput.pdfDataUri });\n        structuredData = genkitStructuredData;\n      }\n\n      if (!structuredData) {\n        const errorMessage = \"AI model did not return structured data after processing.\";\n        console.error(errorMessage, 'Input to prompt:', flowInput);\n        return { jsonOutput: defaultEmptyJsonOutputString, error: errorMessage };\n      }\n      \n      const jsonOutputString = JSON.stringify(structuredData);\n      console.log('Successfully extracted data. Stringified output (snippet):', jsonOutputString.substring(0, 250) + (jsonOutputString.length > 250 ? \"...\" : \"\"));\n      return { jsonOutput: jsonOutputString };\n\n    } catch (error: any) {\n      let errorMessage = `AI processing error: ${error.message}`;\n      if (error.response?.data?.error?.message) { // For Google API specific errors\n        errorMessage += ` Google API Error: ${error.response.data.error.message}`;\n      }\n      console.error('Error during data extraction flow:', error.message, error.stack, 'Input:', flowInput);\n      return { jsonOutput: defaultEmptyJsonOutputString, error: errorMessage };\n    }\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;CAMC,GAED;AACA;AAAA;AACA;AAEA;;;;;;;;AAEA,oCAAoC;AACpC,MAAM,gCAAgC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC7C,YAAY,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAC7B;IAEF,kBAAkB,uIAAA,CAAA,IAAC,CAAC,IAAI,CAAC;QAAC;QAAgB;KAAoB,EAC3D,OAAO,CAAC,gBACR,QAAQ,CAAC;AACd;AAGA,qDAAqD;AACrD,MAAM,iCAAiC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC9C,YAAY,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAChC,OAAO,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AACxC;AAGO,eAAe,uCAAgB,GAAhB,mBAAmB,KAA8B;IACrE,OAAO,uBAAuB;AAChC;AAEA,gDAAgD;AAChD,MAAM,+BAA+B,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IACnD,MAAM;IACN,OAAO;QAAE,QAAQ,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;YAAE,YAAY,8BAA8B,KAAK,CAAC,UAAU;QAAC;IAAG;IAC1F,QAAQ;QAAE,QAAQ,6IAAA,CAAA,yBAAsB;IAAC;IACzC,QAAQ,CAAC;;;;;;;;;;;wBAWa,CAAC;AACzB;AAEA,sFAAsF;AACtF,MAAM,yBAAyB,mHAAA,CAAA,KAAE,CAAC,YAAY,CAAC;IAC7C,MAAM;IACN,OAAO;QAAE,QAAQ,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;YAAE,SAAS,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;QAAoD;IAAG;IAChH,QAAQ;QAAE,QAAQ,6IAAA,CAAA,yBAAsB;IAAC;IACzC,QAAQ,CAAC;;;;;;;;;;;aAWE,CAAC;AACd;AAGA,MAAM,yBAAyB,mHAAA,CAAA,KAAE,CAAC,UAAU,CAC1C;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO;IACL,QAAQ,GAAG,CAAC,CAAC,0CAA0C,EAAE,UAAU,gBAAgB,EAAE;IAErF,MAAM,6BAA+C;QACnD,QAAQ;QAAI,OAAO;QAAI,MAAM;QAAI,mBAAmB;QACpD,qBAAqB;QAAG,SAAS;QAAI,QAAQ;QAAI,WAAW,EAAE;IAChE;IACA,MAAM,+BAA+B,KAAK,SAAS,CAAC;IAEpD,IAAI;QACF,IAAI,iBAA0C;QAE9C,IAAI,UAAU,gBAAgB,KAAK,qBAAqB;YACtD,QAAQ,GAAG,CAAC;YACZ,MAAM,gCAAgC,QAAQ,GAAG,CAAC,uCAAuC;YACzF,IAAI,CAAC,+BAA+B;gBAClC,OAAO;oBAAE,YAAY;oBAA8B,OAAO;gBAAwE;YACpI;YAEA,IAAI;YACJ,IAAI;gBACF,oBAAoB,KAAK,KAAK,CAAC;gBAC9B,IAAI,qBAAqB,kBAAkB,WAAW,EAAE;oBACtD,kBAAkB,WAAW,GAAG,kBAAkB,WAAW,CAAC,OAAO,CAAC,QAAQ;gBAChF;YACH,EAAE,OAAO,GAAQ;gBACf,QAAQ,KAAK,CAAC,sEAAsE,EAAE,OAAO;gBAC7F,OAAO;oBAAE,YAAY;oBAA8B,OAAO,CAAC,kEAAkE,EAAE,EAAE,OAAO,EAAE;gBAAC;YAC7I;YAEA,MAAM,eAAe,IAAI,oKAAA,CAAA,uBAAoB,CAAC;gBAAE,aAAa;YAAkB;YAE/E,MAAM,gBAAgB,UAAU,UAAU,CAAC,SAAS,CAAC,UAAU,UAAU,CAAC,OAAO,CAAC,OAAO;YAEzF,MAAM,UAAU;gBACd,UAAU;oBACR;wBACE,aAAa;4BACX,SAAS;4BACT,UAAU;wBACZ;wBACA,UAAU;4BAAC;gCAAE,MAAM;4BAA0B;yBAAE;oBACjD;iBACD;YACH;YAEA,QAAQ,GAAG,CAAC;YACZ,MAAM,CAAC,aAAa,GAAG,MAAM,aAAa,kBAAkB,CAAC,UAAiB,2BAA2B;YACzG,MAAM,YAAY,aAAa,SAAS,EAAE,CAAC,EAAE,EAAE;YAE/C,IAAI,CAAC,aAAa,UAAU,MAAM,KAAK,KAAK,CAAC,SAAS,CAAC,EAAE,CAAC,kBAAkB,EAAE;gBAC5E,QAAQ,KAAK,CAAC;gBACd,OAAO;oBAAE,YAAY;oBAA8B,OAAO;gBAAiG;YAC7J;YAEA,MAAM,UAAU,SAAS,CAAC,EAAE,CAAC,kBAAkB,CAAC,IAAI,IAAI;YACxD,QAAQ,GAAG,CAAC,+CAA+C,QAAQ,SAAS,CAAC,GAAG;YAEhF,IAAI,CAAC,QAAQ,IAAI,IAAI;gBACjB,QAAQ,IAAI,CAAC;gBACb,OAAO;oBAAE,YAAY;oBAA8B,OAAO;gBAA+C;YAC7G;YAEA,MAAM,EAAE,QAAQ,oBAAoB,EAAE,GAAG,MAAM,uBAAuB;gBAAE;YAAQ;YAChF,iBAAiB;QAEnB,OAAO;YACL,QAAQ,GAAG,CAAC;YACZ,MAAM,EAAE,QAAQ,oBAAoB,EAAE,GAAG,MAAM,6BAA6B;gBAAE,YAAY,UAAU,UAAU;YAAC;YAC/G,iBAAiB;QACnB;QAEA,IAAI,CAAC,gBAAgB;YACnB,MAAM,eAAe;YACrB,QAAQ,KAAK,CAAC,cAAc,oBAAoB;YAChD,OAAO;gBAAE,YAAY;gBAA8B,OAAO;YAAa;QACzE;QAEA,MAAM,mBAAmB,KAAK,SAAS,CAAC;QACxC,QAAQ,GAAG,CAAC,8DAA8D,iBAAiB,SAAS,CAAC,GAAG,OAAO,CAAC,iBAAiB,MAAM,GAAG,MAAM,QAAQ,EAAE;QAC1J,OAAO;YAAE,YAAY;QAAiB;IAExC,EAAE,OAAO,OAAY;QACnB,IAAI,eAAe,CAAC,qBAAqB,EAAE,MAAM,OAAO,EAAE;QAC1D,IAAI,MAAM,QAAQ,EAAE,MAAM,OAAO,SAAS;YACxC,gBAAgB,CAAC,mBAAmB,EAAE,MAAM,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE;QAC3E;QACA,QAAQ,KAAK,CAAC,sCAAsC,MAAM,OAAO,EAAE,MAAM,KAAK,EAAE,UAAU;QAC1F,OAAO;YAAE,YAAY;YAA8B,OAAO;QAAa;IACzE;AACF;;;IA3IoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 529, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/ai/flows/save-to-google-sheet.ts"],"sourcesContent":["\n'use server';\n/**\n * @fileOverview Saves extracted PDF data to a Google Sheet.\n * Each student will be on a new row, with other PDF data repeated.\n * If data for the same documentInstanceId already exists, it's deleted before appending.\n * Operations are performed on the *first sheet* found in the spreadsheet.\n *\n * - saveToGoogleSheet - A function that handles saving data to Google Sheets.\n * - SaveToGoogleSheetInput - The input type for the saveToGoogleSheet function.\n * - SaveToGoogleSheetOutput - The return type for the saveToGoogleSheet function.\n */\n\nimport { ai } from '@/ai/genkit';\nimport { z } from 'genkit';\nimport { ExtractedPdfDataSchema } from '@/ai/schemas/pdf-data-schema';\nimport { google, type sheets_v4 } from 'googleapis';\n\nconst SaveToGoogleSheetInputSchema = z.object({\n  extractedData: ExtractedPdfDataSchema,\n  documentInstanceId: z.string().describe('A unique identifier for this PDF processing instance.'),\n});\nexport type SaveToGoogleSheetInput = z.infer<typeof SaveToGoogleSheetInputSchema>;\n\nconst SaveToGoogleSheetOutputSchema = z.object({\n  success: z.boolean().describe('Whether the save operation was successful.'),\n  message: z.string().describe('A message detailing the outcome of the save operation.'),\n  spreadsheetId: z.string().optional().describe('The ID of the spreadsheet.'),\n  updatedRange: z.string().optional().describe('The range that was updated in A1 notation.'),\n});\nexport type SaveToGoogleSheetOutput = z.infer<typeof SaveToGoogleSheetOutputSchema>;\n\nexport async function saveToGoogleSheet(input: SaveToGoogleSheetInput): Promise<SaveToGoogleSheetOutput> {\n  return saveToGoogleSheetFlow(input);\n}\n\nconst saveToGoogleSheetFlow = ai.defineFlow(\n  {\n    name: 'saveToGoogleSheetFlow',\n    inputSchema: SaveToGoogleSheetInputSchema,\n    outputSchema: SaveToGoogleSheetOutputSchema,\n  },\n  async ({ extractedData: data, documentInstanceId }) => {\n    const spreadsheetId = process.env.GOOGLE_SHEET_ID;\n    const serviceAccountCredsJsonString = process.env.GOOGLE_SERVICE_ACCOUNT_CREDENTIALS_JSON;\n\n    if (!spreadsheetId) {\n      return { success: false, message: 'Google Sheet ID is not configured in environment variables.' };\n    }\n    if (!serviceAccountCredsJsonString) {\n      return { success: false, message: 'Google Service Account credentials are not configured in environment variables.' };\n    }\n\n    let credentials;\n    try {\n      credentials = JSON.parse(serviceAccountCredsJsonString);\n      if (credentials && credentials.private_key) {\n        // Ensure private_key newlines are correctly formatted for the googleapis library\n        credentials.private_key = credentials.private_key.replace(/\\\\n/g, '\\n');\n      }\n    } catch (error: any) {\n      console.error('Failed to parse Google Service Account credentials JSON:', error.message);\n      return { success: false, message: `Invalid Google Service Account credentials JSON format: ${error.message}` };\n    }\n    \n    if (!credentials || !credentials.client_email || !credentials.private_key) {\n        return { success: false, message: 'Parsed Google Service Account credentials missing required fields (client_email or private_key).' };\n    }\n\n    try {\n      const auth = new google.auth.GoogleAuth({\n        credentials,\n        scopes: ['https://www.googleapis.com/auth/spreadsheets'],\n      });\n      const sheets = google.sheets({ version: 'v4', auth });\n\n      // --- Get properties of the first sheet ---\n      let firstSheetProperties;\n      let actualSheetNameUsed: string;\n      let actualSheetIdNumberUsed: number;\n\n      try {\n          const spreadsheetDetails = await sheets.spreadsheets.get({\n            spreadsheetId,\n            fields: 'sheets(properties(sheetId,title))', // Efficiently get only sheetId and title for all sheets\n          });\n\n          if (!spreadsheetDetails.data.sheets || spreadsheetDetails.data.sheets.length === 0) {\n            return { success: false, message: 'The specified spreadsheet contains no sheets.' };\n          }\n          // Assume we operate on the first sheet (gid=0 equivalent)\n          const firstSheet = spreadsheetDetails.data.sheets[0];\n          if (!firstSheet.properties || typeof firstSheet.properties.sheetId !== 'number' || !firstSheet.properties.title) {\n            return { success: false, message: 'Could not retrieve valid properties (ID and Title) for the first sheet.' };\n          }\n          firstSheetProperties = firstSheet.properties;\n          actualSheetNameUsed = firstSheetProperties.title;\n          actualSheetIdNumberUsed = firstSheetProperties.sheetId;\n\n      } catch (e: any) {\n          console.error(\"Failed to get spreadsheet details (for sheetId/title):\", e.message);\n          return { success: false, message: `Failed to get spreadsheet details: ${e.message}` };\n      }\n\n      console.log(`Operating on sheet titled: '${actualSheetNameUsed}' with numerical ID: ${actualSheetIdNumberUsed}`);\n\n      const newHeaderRow = [\n        'DocumentInstanceID',\n        'Classe',\n        'Cours',\n        'Date',\n        'Nom du Professeur',\n        'Nombre des Présents (du PDF)',\n        'Salle N°',\n        'Séance',\n        'N° Étudiant',\n        'Nom & Prénom Étudiant',\n      ];\n      const documentInstanceIdColumnIndex = 0; \n\n      // --- 1. Check and write header if necessary ---\n      let sheetNeedsHeader = true;\n      try {\n        const headerCheckRange = `${actualSheetNameUsed}!A1:${String.fromCharCode(64 + newHeaderRow.length)}1`;\n        const headerCheck = await sheets.spreadsheets.values.get({\n            spreadsheetId,\n            range: headerCheckRange,\n        });\n        if (headerCheck.data.values && headerCheck.data.values.length > 0) {\n            if (JSON.stringify(headerCheck.data.values[0]) === JSON.stringify(newHeaderRow)) {\n                 sheetNeedsHeader = false;\n            }\n        }\n      } catch (getHeaderError: any) {\n          if (getHeaderError.message && (getHeaderError.message.includes(\"Unable to parse range\") || getHeaderError.message.includes(\"Requested entity was not found\"))) {\n              sheetNeedsHeader = true; // Sheet or range doesn't exist, so header is needed\n          } else if (getHeaderError.response && getHeaderError.response.data && getHeaderError.response.data.error && getHeaderError.response.data.error.code === 404) {\n              sheetNeedsHeader = true; // Also indicates entity not found\n          } else {\n            // For other errors, conservatively assume header might be needed or log warning.\n            console.warn(\"Could not definitively check for header due to an error. Proceeding as if header is needed. Error:\", getHeaderError.message);\n            sheetNeedsHeader = true; \n          }\n      }\n\n      // --- 2. Find and delete existing rows for this documentInstanceId ---\n      if (!sheetNeedsHeader) { \n        console.log(`Checking for existing data with DocumentInstanceID: ${documentInstanceId} in sheet: ${actualSheetNameUsed}`);\n        const dataToSearch = await sheets.spreadsheets.values.get({\n            spreadsheetId,\n            range: `${actualSheetNameUsed}!A:A`, \n        });\n\n        const rowsToDelete: sheets_v4.Schema$Request[] = [];\n        if (dataToSearch.data.values) {\n            for (let i = 0; i < dataToSearch.data.values.length; i++) {\n                if (dataToSearch.data.values[i][documentInstanceIdColumnIndex] === documentInstanceId) {\n                    rowsToDelete.push({\n                        deleteDimension: {\n                            range: {\n                                sheetId: actualSheetIdNumberUsed, \n                                dimension: 'ROWS',\n                                startIndex: i, \n                                endIndex: i + 1,\n                            },\n                        },\n                    });\n                }\n            }\n        }\n\n        if (rowsToDelete.length > 0) {\n            rowsToDelete.sort((a, b) => (b.deleteDimension!.range!.startIndex!) - (a.deleteDimension!.range!.startIndex!));\n            console.log(`Found ${rowsToDelete.length} existing row(s) for DocumentInstanceID ${documentInstanceId}. Deleting them.`);\n            await sheets.spreadsheets.batchUpdate({\n                spreadsheetId,\n                requestBody: {\n                    requests: rowsToDelete,\n                },\n            });\n        } else {\n            console.log(`No existing rows found for DocumentInstanceID ${documentInstanceId}.`);\n        }\n      }\n\n\n      // --- 3. Prepare and append new data ---\n      const dataRowsToAppend: (string | number | boolean | null)[][] = [];\n      const commonData = [\n        data.classe ?? \"\",\n        data.cours ?? \"\",\n        data.date ?? \"\",\n        data.nom_du_professeur ?? \"\",\n        data.nombre_des_présents ?? 0,\n        data.salle_n ?? \"\",\n        data.séance ?? \"\",\n      ];\n\n      if (data.présences && data.présences.length > 0) {\n        for (const student of data.présences) {\n          dataRowsToAppend.push([\n            documentInstanceId, \n            ...commonData,\n            student.n ?? \"\",\n            student.nom_prénom ?? \"\",\n          ]);\n        }\n      } else {\n        dataRowsToAppend.push([\n          documentInstanceId, \n          ...commonData,\n          \"\", \n          \"\", \n        ]);\n      }\n      \n      const finalRowsForSheet = [];\n      if (sheetNeedsHeader) {\n          console.log(\"Sheet requires header. Prepending header row.\");\n          finalRowsForSheet.push(newHeaderRow);\n      }\n      finalRowsForSheet.push(...dataRowsToAppend);\n\n      if (finalRowsForSheet.length === 0 || (finalRowsForSheet.length === 1 && sheetNeedsHeader && dataRowsToAppend.length === 0)) {\n        return {\n            success: true,\n            message: 'No new data rows to append to Google Sheet.',\n            spreadsheetId: spreadsheetId,\n        };\n      }\n\n      const appendResponse = await sheets.spreadsheets.values.append({\n        spreadsheetId,\n        range: `${actualSheetNameUsed}!A1`, \n        valueInputOption: 'USER_ENTERED', \n        insertDataOption: 'INSERT_ROWS', \n        requestBody: {\n          values: finalRowsForSheet,\n        },\n      });\n\n      console.log('Successfully saved/updated data in Google Sheet:', appendResponse.data);\n      return {\n        success: true,\n        message: `Data successfully saved/updated in Google Sheet '${actualSheetNameUsed}'. ${dataRowsToAppend.length} data row(s) processed for DocumentInstanceID ${documentInstanceId}. ${sheetNeedsHeader ? 'Header was also written.' : ''}`,\n        spreadsheetId: appendResponse.data.spreadsheetId,\n        updatedRange: appendResponse.data.updates?.updatedRange,\n      };\n    } catch (error: any) {\n      console.error('Error saving to Google Sheet:', error.message, error.stack, error.response?.data?.error);\n      let errorMessage = `Failed to save to Google Sheet: ${error.message}`;\n      if (error.response?.data?.error?.message) {\n        errorMessage += ` Google API Error: ${error.response.data.error.message}`;\n      }\n      return { success: false, message: errorMessage };\n    }\n  }\n);\n"],"names":[],"mappings":";;;;;AAEA;;;;;;;;;CASC,GAED;AACA;AAAA;AACA;AACA;;;;;;;;AAEA,MAAM,+BAA+B,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC5C,eAAe,6IAAA,CAAA,yBAAsB;IACrC,oBAAoB,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;AAC1C;AAGA,MAAM,gCAAgC,uIAAA,CAAA,IAAC,CAAC,MAAM,CAAC;IAC7C,SAAS,uIAAA,CAAA,IAAC,CAAC,OAAO,GAAG,QAAQ,CAAC;IAC9B,SAAS,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,CAAC;IAC7B,eAAe,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;IAC9C,cAAc,uIAAA,CAAA,IAAC,CAAC,MAAM,GAAG,QAAQ,GAAG,QAAQ,CAAC;AAC/C;AAGO,eAAe,uCAAe,GAAf,kBAAkB,KAA6B;IACnE,OAAO,sBAAsB;AAC/B;AAEA,MAAM,wBAAwB,mHAAA,CAAA,KAAE,CAAC,UAAU,CACzC;IACE,MAAM;IACN,aAAa;IACb,cAAc;AAChB,GACA,OAAO,EAAE,eAAe,IAAI,EAAE,kBAAkB,EAAE;IAChD,MAAM,gBAAgB,QAAQ,GAAG,CAAC,eAAe;IACjD,MAAM,gCAAgC,QAAQ,GAAG,CAAC,uCAAuC;IAEzF,IAAI,CAAC,eAAe;QAClB,OAAO;YAAE,SAAS;YAAO,SAAS;QAA8D;IAClG;IACA,IAAI,CAAC,+BAA+B;QAClC,OAAO;YAAE,SAAS;YAAO,SAAS;QAAkF;IACtH;IAEA,IAAI;IACJ,IAAI;QACF,cAAc,KAAK,KAAK,CAAC;QACzB,IAAI,eAAe,YAAY,WAAW,EAAE;YAC1C,iFAAiF;YACjF,YAAY,WAAW,GAAG,YAAY,WAAW,CAAC,OAAO,CAAC,QAAQ;QACpE;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,4DAA4D,MAAM,OAAO;QACvF,OAAO;YAAE,SAAS;YAAO,SAAS,CAAC,wDAAwD,EAAE,MAAM,OAAO,EAAE;QAAC;IAC/G;IAEA,IAAI,CAAC,eAAe,CAAC,YAAY,YAAY,IAAI,CAAC,YAAY,WAAW,EAAE;QACvE,OAAO;YAAE,SAAS;YAAO,SAAS;QAAmG;IACzI;IAEA,IAAI;QACF,MAAM,OAAO,IAAI,mJAAA,CAAA,SAAM,CAAC,IAAI,CAAC,UAAU,CAAC;YACtC;YACA,QAAQ;gBAAC;aAA+C;QAC1D;QACA,MAAM,SAAS,mJAAA,CAAA,SAAM,CAAC,MAAM,CAAC;YAAE,SAAS;YAAM;QAAK;QAEnD,4CAA4C;QAC5C,IAAI;QACJ,IAAI;QACJ,IAAI;QAEJ,IAAI;YACA,MAAM,qBAAqB,MAAM,OAAO,YAAY,CAAC,GAAG,CAAC;gBACvD;gBACA,QAAQ;YACV;YAEA,IAAI,CAAC,mBAAmB,IAAI,CAAC,MAAM,IAAI,mBAAmB,IAAI,CAAC,MAAM,CAAC,MAAM,KAAK,GAAG;gBAClF,OAAO;oBAAE,SAAS;oBAAO,SAAS;gBAAgD;YACpF;YACA,0DAA0D;YAC1D,MAAM,aAAa,mBAAmB,IAAI,CAAC,MAAM,CAAC,EAAE;YACpD,IAAI,CAAC,WAAW,UAAU,IAAI,OAAO,WAAW,UAAU,CAAC,OAAO,KAAK,YAAY,CAAC,WAAW,UAAU,CAAC,KAAK,EAAE;gBAC/G,OAAO;oBAAE,SAAS;oBAAO,SAAS;gBAA0E;YAC9G;YACA,uBAAuB,WAAW,UAAU;YAC5C,sBAAsB,qBAAqB,KAAK;YAChD,0BAA0B,qBAAqB,OAAO;QAE1D,EAAE,OAAO,GAAQ;YACb,QAAQ,KAAK,CAAC,0DAA0D,EAAE,OAAO;YACjF,OAAO;gBAAE,SAAS;gBAAO,SAAS,CAAC,mCAAmC,EAAE,EAAE,OAAO,EAAE;YAAC;QACxF;QAEA,QAAQ,GAAG,CAAC,CAAC,4BAA4B,EAAE,oBAAoB,qBAAqB,EAAE,yBAAyB;QAE/G,MAAM,eAAe;YACnB;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;YACA;SACD;QACD,MAAM,gCAAgC;QAEtC,iDAAiD;QACjD,IAAI,mBAAmB;QACvB,IAAI;YACF,MAAM,mBAAmB,GAAG,oBAAoB,IAAI,EAAE,OAAO,YAAY,CAAC,KAAK,aAAa,MAAM,EAAE,CAAC,CAAC;YACtG,MAAM,cAAc,MAAM,OAAO,YAAY,CAAC,MAAM,CAAC,GAAG,CAAC;gBACrD;gBACA,OAAO;YACX;YACA,IAAI,YAAY,IAAI,CAAC,MAAM,IAAI,YAAY,IAAI,CAAC,MAAM,CAAC,MAAM,GAAG,GAAG;gBAC/D,IAAI,KAAK,SAAS,CAAC,YAAY,IAAI,CAAC,MAAM,CAAC,EAAE,MAAM,KAAK,SAAS,CAAC,eAAe;oBAC5E,mBAAmB;gBACxB;YACJ;QACF,EAAE,OAAO,gBAAqB;YAC1B,IAAI,eAAe,OAAO,IAAI,CAAC,eAAe,OAAO,CAAC,QAAQ,CAAC,4BAA4B,eAAe,OAAO,CAAC,QAAQ,CAAC,iCAAiC,GAAG;gBAC3J,mBAAmB,MAAM,oDAAoD;YACjF,OAAO,IAAI,eAAe,QAAQ,IAAI,eAAe,QAAQ,CAAC,IAAI,IAAI,eAAe,QAAQ,CAAC,IAAI,CAAC,KAAK,IAAI,eAAe,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,IAAI,KAAK,KAAK;gBACzJ,mBAAmB,MAAM,kCAAkC;YAC/D,OAAO;gBACL,iFAAiF;gBACjF,QAAQ,IAAI,CAAC,sGAAsG,eAAe,OAAO;gBACzI,mBAAmB;YACrB;QACJ;QAEA,uEAAuE;QACvE,IAAI,CAAC,kBAAkB;YACrB,QAAQ,GAAG,CAAC,CAAC,oDAAoD,EAAE,mBAAmB,WAAW,EAAE,qBAAqB;YACxH,MAAM,eAAe,MAAM,OAAO,YAAY,CAAC,MAAM,CAAC,GAAG,CAAC;gBACtD;gBACA,OAAO,GAAG,oBAAoB,IAAI,CAAC;YACvC;YAEA,MAAM,eAA2C,EAAE;YACnD,IAAI,aAAa,IAAI,CAAC,MAAM,EAAE;gBAC1B,IAAK,IAAI,IAAI,GAAG,IAAI,aAAa,IAAI,CAAC,MAAM,CAAC,MAAM,EAAE,IAAK;oBACtD,IAAI,aAAa,IAAI,CAAC,MAAM,CAAC,EAAE,CAAC,8BAA8B,KAAK,oBAAoB;wBACnF,aAAa,IAAI,CAAC;4BACd,iBAAiB;gCACb,OAAO;oCACH,SAAS;oCACT,WAAW;oCACX,YAAY;oCACZ,UAAU,IAAI;gCAClB;4BACJ;wBACJ;oBACJ;gBACJ;YACJ;YAEA,IAAI,aAAa,MAAM,GAAG,GAAG;gBACzB,aAAa,IAAI,CAAC,CAAC,GAAG,IAAM,AAAC,EAAE,eAAe,CAAE,KAAK,CAAE,UAAU,GAAM,EAAE,eAAe,CAAE,KAAK,CAAE,UAAU;gBAC3G,QAAQ,GAAG,CAAC,CAAC,MAAM,EAAE,aAAa,MAAM,CAAC,wCAAwC,EAAE,mBAAmB,gBAAgB,CAAC;gBACvH,MAAM,OAAO,YAAY,CAAC,WAAW,CAAC;oBAClC;oBACA,aAAa;wBACT,UAAU;oBACd;gBACJ;YACJ,OAAO;gBACH,QAAQ,GAAG,CAAC,CAAC,8CAA8C,EAAE,mBAAmB,CAAC,CAAC;YACtF;QACF;QAGA,yCAAyC;QACzC,MAAM,mBAA2D,EAAE;QACnE,MAAM,aAAa;YACjB,KAAK,MAAM,IAAI;YACf,KAAK,KAAK,IAAI;YACd,KAAK,IAAI,IAAI;YACb,KAAK,iBAAiB,IAAI;YAC1B,KAAK,mBAAmB,IAAI;YAC5B,KAAK,OAAO,IAAI;YAChB,KAAK,MAAM,IAAI;SAChB;QAED,IAAI,KAAK,SAAS,IAAI,KAAK,SAAS,CAAC,MAAM,GAAG,GAAG;YAC/C,KAAK,MAAM,WAAW,KAAK,SAAS,CAAE;gBACpC,iBAAiB,IAAI,CAAC;oBACpB;uBACG;oBACH,QAAQ,CAAC,IAAI;oBACb,QAAQ,UAAU,IAAI;iBACvB;YACH;QACF,OAAO;YACL,iBAAiB,IAAI,CAAC;gBACpB;mBACG;gBACH;gBACA;aACD;QACH;QAEA,MAAM,oBAAoB,EAAE;QAC5B,IAAI,kBAAkB;YAClB,QAAQ,GAAG,CAAC;YACZ,kBAAkB,IAAI,CAAC;QAC3B;QACA,kBAAkB,IAAI,IAAI;QAE1B,IAAI,kBAAkB,MAAM,KAAK,KAAM,kBAAkB,MAAM,KAAK,KAAK,oBAAoB,iBAAiB,MAAM,KAAK,GAAI;YAC3H,OAAO;gBACH,SAAS;gBACT,SAAS;gBACT,eAAe;YACnB;QACF;QAEA,MAAM,iBAAiB,MAAM,OAAO,YAAY,CAAC,MAAM,CAAC,MAAM,CAAC;YAC7D;YACA,OAAO,GAAG,oBAAoB,GAAG,CAAC;YAClC,kBAAkB;YAClB,kBAAkB;YAClB,aAAa;gBACX,QAAQ;YACV;QACF;QAEA,QAAQ,GAAG,CAAC,oDAAoD,eAAe,IAAI;QACnF,OAAO;YACL,SAAS;YACT,SAAS,CAAC,iDAAiD,EAAE,oBAAoB,GAAG,EAAE,iBAAiB,MAAM,CAAC,8CAA8C,EAAE,mBAAmB,EAAE,EAAE,mBAAmB,6BAA6B,IAAI;YACzO,eAAe,eAAe,IAAI,CAAC,aAAa;YAChD,cAAc,eAAe,IAAI,CAAC,OAAO,EAAE;QAC7C;IACF,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,iCAAiC,MAAM,OAAO,EAAE,MAAM,KAAK,EAAE,MAAM,QAAQ,EAAE,MAAM;QACjG,IAAI,eAAe,CAAC,gCAAgC,EAAE,MAAM,OAAO,EAAE;QACrE,IAAI,MAAM,QAAQ,EAAE,MAAM,OAAO,SAAS;YACxC,gBAAgB,CAAC,mBAAmB,EAAE,MAAM,QAAQ,CAAC,IAAI,CAAC,KAAK,CAAC,OAAO,EAAE;QAC3E;QACA,OAAO;YAAE,SAAS;YAAO,SAAS;QAAa;IACjD;AACF;;;IAhOoB;;AAAA,+OAAA","debugId":null}},
    {"offset": {"line": 806, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 862, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/page.tsx <module evaluation> from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/page.tsx <module evaluation>\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAoR,GACjT,kDACA","debugId":null}},
    {"offset": {"line": 876, "column": 0}, "map": {"version":3,"sources":["file:///home/user/studio/src/app/page.tsx/proxy.mjs"],"sourcesContent":["import { registerClientReference } from \"react-server-dom-turbopack/server.edge\";\nexport default registerClientReference(\n    function() { throw new Error(\"Attempted to call the default export of [project]/src/app/page.tsx from the server, but it's on the client. It's not possible to invoke a client function from the server, it can only be rendered as a Component or passed to props of a Client Component.\"); },\n    \"[project]/src/app/page.tsx\",\n    \"default\",\n);\n"],"names":[],"mappings":";;;AAAA;;uCACe,CAAA,GAAA,qPAAA,CAAA,0BAAuB,AAAD,EACjC;IAAa,MAAM,IAAI,MAAM;AAAgQ,GAC7R,8BACA","debugId":null}},
    {"offset": {"line": 890, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}}]
}